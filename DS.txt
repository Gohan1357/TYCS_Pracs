PRAC 1- WORD CLOUD 

from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
import wikipedia as wp
result = wp.page('Computer Science')
final_result = result.content
print(final_result)
def plot_wordcloud(wc):
    plt.axis("off")
    plt.figure(figsize=(10,10))
    plt.imshow(wc)
    plt.show()
wc=WordCloud(width=500, height=500, background_color="blue", random_state=10,stopwords=STOPWORDS).generate(final_result)
wc.to_file("cs.png")
plot_wordcloud(wc)




PRAC 2A-WEB SCRAPING 

import pandas as pd
from bs4 import BeautifulSoup
from urllib.request import urlopen


url = "https://en.wikipedia.org/wiki/List_of_Asian_countries_by_area"
page = urlopen(url)
html_page = page.read().decode("utf-8")
soup = BeautifulSoup(html_page, "html.parser")
table = soup.find("table")


print(table)


SrNo = []
Country = []
Area = []


rows = table.find("tbody").find_all("tr")
for row in rows:
    cells = row.find_all("td")
    if cells:
        SrNo.append(cells[0].get_text().strip("\n"))
        Country.append(cells[1].get_text().strip("\xa0").strip("\n").strip("\[2]*"))
        Area.append(cells[3].get_text().strip("\n").replace(",", ""))


countries_df = pd.DataFrame()
countries_df["ID"] = SrNo
countries_df["Country Name"] = Country
countries_df["Area"] = Area


print(countries_df.head(10))




PRAC 2B- JSON SCRAPPING 


# PRAC 2 JSON SCRAPPING


import pandas as pd
import urllib.request
import json


url = "https://jsonplaceholder.typicode.com/users"
response = urllib.request.urlopen(url)
data = json.loads(response.read())


id = []
username = []
email = []


for item in data:
    if "id" in item.keys():
        id.append(item["id"])
    else:
        id.append("NA")
       
    if "username" in item.keys():
        username.append(item["username"])
    else:
        username.append("NA")
       
    if "email" in item.keys():
        email.append(item["email"])
    else:
        email.append("NA")


user_df = pd.DataFrame()
user_df["User ID"] = id
user_df["User Name"] = username
user_df["Email Address"] = email


print(user_df.head(10))





PRAC 3:MT CARS 

#Perform exploratory data analysis of MTcars.csv in R
cars_df=read.csv("mtcars.csv") #Read
View(cars_df)
dim(cars_df)
names(cars_df)
row.names(cars_df)=cars_df$model#setting the
View(cars_df)
row.names(cars_df)
#Slicing
cars_df=cars_df[,-1] #remove model col (negative index for discarding the col) #[r,c]
cars_df[1:3,1:3] #[r,c]
cars_df[,1:3] #[r,c]
  


library(dplyr)#Like the pandas package in python for    dataset manipulation 

#Select function -selecting specific columns for dataframe
df1=select(cars_df,mpg:hp)
View(df1)


#ALTERNATIVE  WAY 

df2=cars_df %>% select(mpg:hp)
View(df2)

#The Above two statements perform the same function 

#SElect function by creating a vector 
df3=cars_df %>% select(c(mpg,hp,wt,gear))
View(df3)



#Filter function- selecting specific rows
df4=cars_df%>% filter(gear==4)
View(df4)


#filter where gear=5 or mpg>21,only mpg and gear should be selected 

df1=cars_df%>% filter(gear==5|mpg>21) %>% select(c(mpg,gear))
View(df1)

#filter records where cyl=6  and mpg<20 only mpg and cyl to be displayed 

df5=cars_df%>% filter(cyl==6 & mpg<20) %>% select(c(cyl,mpg))
View(df5)



#Sorting data on the basis of specific columns 
#Sort data on descending order of mpg

df1=cars_df%>%arrange(desc(mpg),wt)#Also multiple sorting 



View(df1)

#Renaming function-> renaming column names 
df1=cars_df %>% rename(MilesPerGallon=mpg,Cylinder=cyl)
View(df1)


#Mutate function - Add new columns on the basis of existing columns 
#create a new column power=hp*wt 


df1=cars_df%>% mutate(Power=hp*wt)
View(df1)


#Group_by and summarise -to segregate data  as per categorical value and summarise with mean,max,no,min etc 
#here in this dataset there are 3 categorical variables 

str(df1)
df1$gear=as.factor(df1$gear)


df1_summary=df1 %>% group_by(df1$gear) %>% summarise(no_of_entries=n(),mean_mpg=mean(mpg),mean_disp=mean(disp))

df1_summary






PRAC 4:PYTHON EDA :TITANIC

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

import os
os.getcwd()
titanic=pd.read_csv("train.csv")
titanic.head()
titanic.info() #Compared to str in R
titanic.describe()   #shows the mean ,upper quartile ,lower quartile 
titanic.isnull().sum()
titanic_cleaned=titanic.drop(['PassengerId','Name','Ticket','Fare','Cabin'],axis=1)
titanic_cleaned.info
#Plotting Count of a passenger who survived on the basis of sex
sns.catplot(x='Sex',hue='Survived',kind='count',data=titanic_cleaned)
titanic_cleaned.groupby(['Sex','Survived'])['Survived'].count()
#Generating heatmap for sex -Survived relationship
group1=titanic_cleaned.groupby(['Sex','Survived'])
gender_survived=group1.size().unstack()
gender_survived

#Generating heatmap for p class -Survived relationship
group1=titanic_cleaned.groupby(['Pclass','Survived'])
gender_survived=group1.size().unstack() 
sns.heatmap(gender_survived,annot=True,fmt="d") #d represents integer annotation
#violin plot is used forvisualising the distribution of a numerical varoiable
sns.violinplot(x="Sex",y="Age",hue="Survived",data=titanic_cleaned,split=True)
#Imputing of age variable
print("Oldest person on board",titanic_cleaned['Age'].max())
#Youngest person onboard
print("Youngest person on board",titanic_cleaned['Age'].min())
#Average age
print("Average age of people on board",titanic_cleaned['Age'].mean())
def impute(cols):
    Age=cols[0]
    Pclass=cols[1]
    if pd.isnull(Age):
        if Pclass==1:
            return 34
        elif Pclass==2:
            return 29
        else:
            return 24
    else:
        return Age
titanic_cleaned['Age']=titanic_cleaned[["Age",'Pclass']].apply(impute,axis=1)
titanic_cleaned.isnull().sum()
titanic_cleaned.corr(method='pearson')
sns.heatmap(titanic_cleaned.corr(method="pearson"),annot=True,vmax=1)




# EXPERIENCE VS SALARY 

import numpy as np
from sklearn import datasets
x,y,coef=datasets.make_regression(n_features=1,n_informative =1,noise=10,coef=True,random_state=0)
  #feature is independent  variable,informative is dependent variable
x=np.interp(x,(x.min(),x.max()),(0,20))
print(len(x))
print(x)
y=np.interp(y,(y.min(),y.max()),(20000,150000))
print(len(y))
print(y)
import matplotlib.pyplot as plt 
plt.plot(x,y,'.')
plt.xlabel("years of experience")
plt.ylabel("Salary")
plt.title("Expereince vs Salary")
from sklearn.linear_model import LinearRegression
reg_model=LinearRegression() # Creating a object of type Linear Regression

reg_model.fit(x,y)

y_pred=reg_model.predict(x)
plt.plot(x,y_pred,color="black")
plt.plot(x,y,'.') # . represents scatter plot
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.title("Experience vs Salary")






PRAC 5 : 

#Write a python program to simulate linear model Y=10+7*x+e for random 100 samples and visualize univariate linear regression on it.
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression


# First Regression Model
#x1 = [[13.0]]
#y1 = reg_model.predict(x1)
#print(np.round(y1))

# Second Regression Model
reg_model1 = LinearRegression()

x = np.random.rand(100, 1)
y_intercept = 10
slope = 7
error = np.random.rand(100, 1)
y = y_intercept + slope * x + error

reg_model1.fit(x, y)
y_pred = reg_model1.predict(x)

# Plotting
plt.scatter(x, y, s=10)
plt.xlabel("X")
plt.ylabel("Y")
plt.plot(x, y_pred, color="black")

plt.show()



PRAC 6:MULTIVARIATE LINEAR REGRESSION

# Write a python program to implement multiple linear regression on the Dataset Boston.csv
# The dataset provides Housing Values in SUburbs of Boston
#The medv(Price) variable is the target variable
#Data Description/*
""" """

import pandas as pd
import matplotlib.pyplot as plt
import sklearn
boston=pd.read_csv("Boston.csv")
boston.head()
boston.info()#to get the structure of dataset

boston.drop(columns="Unnamed: 0") #To drop the unnamed serial Number Column
boston.info()

boston_x=pd.DataFrame(boston.iloc[:,:13])#iloc(index location) is a function used to split data (before comma is rows ,after comma is columns )
boston_y=pd.DataFrame(boston.iloc[:,-1])   #-1 is the last value ,but in R we use minus toexculde something

#boston_x.head()
#boston_y.head()


from sklearn.model_selection import train_test_split
#train_test_split is  used to obtain randomized data and split the data 
X_train,X_test,Y_train,Y_test=train_test_split(boston_x,boston_y,test_size=0.3)#Here the test Data is 30%
print("xtrain Shape ",X_train.shape)
print("ytrain Shape ",Y_train.shape)
print("xtest Shape ",X_test.shape)
print("ytest Shape ",Y_test.shape)














from sklearn.linear_model import LinearRegression

regression=LinearRegression()

regression.fit(X_train,Y_train)#Applying Regression Model on the trained model 

Y_pred_linear=regression.predict(X_test)#To predict the Y values using the regression model

Y_pred_df=pd.DataFrame(Y_pred_linear,columns=["Predicted"])

Y_pred_df.head()

plt.scatter(Y_test,Y_pred_linear,c="green")
plt.xlabel("Actual Price(medv)")
plt.ylabel("Predicted Price(medv)")
plt.title("Actual vs Predicted")






PRAC 7-CANCER DATASET 

# K Nearest Neigbour Algorithm for Cancer Dataset 
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
from sklearn.datasets import load_breast_cancer

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import seaborn as sns


breast_cancer_df=load_breast_cancer()
#retrieving Independent variables
x=pd.DataFrame(breast_cancer_df.data,columns=breast_cancer_df.feature_names)
x.head()
#Retrieving Dependent Variables
x=x[["mean area","mean compactness"]]
x.head()


        


y=pd.Categorical.from_codes(breast_cancer_df.target,breast_cancer_df.target_names)
print(y)
# to make a single cateogotical variable benign as 0 and 1 where 0 is malignant and 1 is benign 

y=pd.get_dummies(y,drop_first=True)
print(y)
X_train,X_test,Y_train,Y_test=train_test_split(x,y,random_state=1)#Random_state is used to randomize everytime the function is executed

knn=KNeighborsClassifier(n_neighbors=5,metric="euclidean")
knn.fit(X_train,Y_train)
sns.set()
sns.scatterplot(x="mean area",y="mean compactness",hue="benign",data=X_test.join(Y_test,how="outer"))

y_pred=knn.predict(X_test)
plt.scatter(X_test["mean area"],X_test["mean compactness"],c=y_pred,cmap="coolwarm",alpha=0.7)
#Get the confusion matrix on the Actual Values and Predicted Values 
cf=confusion_matrix(Y_test,y_pred)
print(cf)

labels=["True Negative ","False Positive","False Negative","True Positive"]

labels=np.asarray(labels).reshape(2,2)
categories=["Zero","One"]

ax=plt.subplot()

#Generating a heatmap 

sns.heatmap(cf,annot=True,ax=ax)
ax.set_xlabel("Predicted Values")

ax.set_ylabel("Actual  Values")


ax.set_title("Confusion Matrix")

ax.xaxis.set_ticklabels(["Malignant","Benign"])
ax.yaxis.set_ticklabels(["Malignant","Benign"])













